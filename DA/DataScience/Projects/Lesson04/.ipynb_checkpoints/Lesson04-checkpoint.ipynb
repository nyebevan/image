{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical computation\n",
    "import pandas as pd #data wrangling\n",
    "import matplotlib.pyplot as plt #plotting package\n",
    "#Next line helps with rendering plots\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl #add'l plotting functionality\n",
    "import seaborn as sns #a fancy plotting package\n",
    "mpl.rcParams['figure.dpi'] = 400 #high res figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the Coefficients and Intercepts of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = np.linspace(0.01,0.99,99)\n",
    "print(X_log[:5], '...', X_log[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(X_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 400 #high res figures\n",
    "plt.plot(X_log, y_log)\n",
    "plt.title('Natural logarithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent to Find Optimal Parameter Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 16: Using Gradient Descent to Minimize a Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = np.linspace(-3,5,81)\n",
    "print(X_poly[:5], '...', X_poly[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X):\n",
    "    return X * (X-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly = cost_function(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_poly, y_poly)\n",
    "plt.xlabel('Parameter value')\n",
    "plt.ylabel('Cost function')\n",
    "plt.title('Error surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X):\n",
    "    return (2*X) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next = x_start - gradient(x_start)*learning_rate\n",
    "x_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_poly, y_poly)\n",
    "plt.plot([x_start, x_next], [cost_function(x_start), cost_function(x_next)], '-o')\n",
    "plt.xlabel('Parameter value')\n",
    "plt.ylabel('Cost function')\n",
    "plt.legend(['Error surface', 'Gradient descent path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 15\n",
    "x_path = np.empty(iterations,)\n",
    "x_path[0] = x_start\n",
    "for iteration_count in range(1,iterations):\n",
    "    derivative = gradient(x_path[iteration_count-1])\n",
    "    x_path[iteration_count] = x_path[iteration_count-1] - (derivative*learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_poly, y_poly)\n",
    "plt.plot(x_path, cost_function(x_path), '-o')\n",
    "plt.xlabel('Parameter value')\n",
    "plt.ylabel('Cost function')\n",
    "plt.legend(['Error surface', 'Gradient descent path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: adjust the path in the following cell to the location where you saved the cleaned data from Chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../Data/Chapter_1_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset column list to features as in Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_response = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_response[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_response[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_remove = ['ID', 'SEX', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                   'EDUCATION_CAT', 'graduate school', 'high school', 'none',\n",
    "                   'others', 'university']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_response = [item for item in features_response if item not in items_to_remove]\n",
    "features_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[features_response].corr()\n",
    "corr.iloc[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 400 #high res figures\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values,\n",
    "            center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_syn_lin, y_syn_lin = make_regression(n_samples=100, n_features=1, n_informative=1,\n",
    "                       n_targets=1, bias=0.0, effective_rank=None,\n",
    "                       tail_strength=0.5, noise=10.0, shuffle=True,\n",
    "                       coef=False, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, r, p, std = linregress(X_syn_lin.reshape(len(X_syn_lin),), y_syn_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_regression = np.array([-3, 3])\n",
    "y_regression = m*x_regression + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_syn_lin, y_syn_lin)\n",
    "plt.plot(x_regression, y_regression, 'r-')\n",
    "plt.title('Synthetic linear data and line of best fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_syn_lin = np.append(X_syn_lin, 10)\n",
    "y_syn_lin = np.append(y_syn_lin, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, r, p, std = linregress(X_syn_lin.reshape(len(X_syn_lin),), y_syn_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_regression = np.array([-3, 10])\n",
    "y_regression = m*x_regression + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_syn_lin, y_syn_lin)\n",
    "plt.plot(x_regression, y_regression, 'r-')\n",
    "plt.title('Synthetic linear data with outlier and line of best fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Motivation for Regularization: the Bias-Variance Trade-off\n",
    "Generate quadratic data with random noise to illustrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=9)\n",
    "n_points = 20\n",
    "X = np.random.uniform(0, 11, n_points)\n",
    "X = np.sort(X)\n",
    "Y = (-X+2) * (X-9) + np.random.normal(0, 3, n_points)\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_fit = np.polyfit(X, Y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to take in the polynomial coefficients and produce the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fun(X, p):\n",
    "    Y = np.zeros_like(X)\n",
    "    power = len(p)-1\n",
    "    for coefficient in p:\n",
    "        Y = Y + coefficient*X**power\n",
    "        power = power - 1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_fun(X,lin_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the models over a more continuous range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_x = np.linspace(0,11,333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.get_cmap('tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, label='Data', color=cmap(0))\n",
    "plt.plot(curve_x, poly_fun(curve_x,lin_fit), label='Underfit model', color=cmap(1))\n",
    "plt.plot(curve_x, poly_fun(curve_x,np.polyfit(X, Y, 15)), label='Overfit model', color=cmap(2))\n",
    "plt.plot(curve_x, poly_fun(curve_x,np.polyfit(X, Y, 2)), label='Ideal model', color=cmap(3))\n",
    "plt.legend(loc=[0.17, 0.1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.ylim([-20, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 17: Generating and Modeling Synthetic Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synthetic, y_synthetic = \\\n",
    "make_classification(n_samples=1000, n_features=200, n_informative=3, n_redundant=10,\n",
    "                    n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None,\n",
    "                    flip_y=0.01, class_sep=0.8, hypercube=True, shift=0.0, scale=1.0,\n",
    "                    shuffle=True, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_synthetic.shape, y_synthetic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_index in range(4):\n",
    "    plt.subplot(2,2,plot_index+1)\n",
    "    plt.hist(X_synthetic[:,plot_index])\n",
    "    plt.title('Histogram for feature {}'.format(plot_index+1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_syn_train, X_syn_test, y_syn_train, y_syn_test = train_test_split(\n",
    "X_synthetic, y_synthetic,\n",
    "test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_syn = \\\n",
    "LogisticRegression(solver='liblinear', penalty='l1', C=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_syn.fit(X_syn_train, y_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_syn_train_predict_proba = lr_syn.predict_proba(X_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_syn_train, y_syn_train_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_syn_test_predict_proba = lr_syn.predict_proba(X_syn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_syn_test, y_syn_test_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_syn.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso (L1) and Ridge (L2) Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays of polynomial features for training and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = X.reshape(20,-1)\n",
    "plot_features = curve_x.reshape(333,-1)\n",
    "for power in range (2,16):\n",
    "    power_array = X.reshape(20,-1)**power\n",
    "    poly_features = np.append(poly_features, power_array.reshape(20,-1), axis=1)\n",
    "    plot_power_array = curve_x.reshape(333,-1)**power\n",
    "    plot_features = np.append(plot_features, plot_power_array.reshape(333,-1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression with ridge penalty. Feature scaling is performed by the regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Ridge(alpha=0.001, fit_intercept=True, normalize=True,\n",
    "                        copy_X=True, max_iter=None, tol=0.001,\n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(poly_features, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(plot_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, label='Data', color=cmap(0))\n",
    "plt.plot(curve_x, poly_fun(curve_x,np.polyfit(X, Y, 15)), label='Overfit model', color=cmap(2))\n",
    "plt.plot(curve_x, poly_fun(curve_x,np.polyfit(X, Y, 2)), label='Ideal model', color=cmap(3))\n",
    "plt.plot(curve_x, Y_pred, label='Regularized model', color=cmap(4), linestyle='--')\n",
    "plt.legend(loc=[0.17, 0.1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.ylim([-20, 20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation: Choosing the Regularization Parameter and Other Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for `StratifiedKFold`, `shuffle=False` by default, the opposite behavior of `train_test_split` which we have been using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = KFold(n_splits=n_folds, shuffle=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kfolds(k_folds_iterator):\n",
    "    fold_counter = 0\n",
    "    for train_index, test_index in k_folds_iterator.split(X_syn_train, y_syn_train):\n",
    "\n",
    "        #Axis to hold the plot of this fold\n",
    "        ax = plt.subplot(n_folds,1,fold_counter+1)\n",
    "\n",
    "        #Background rectangle representing all samples\n",
    "        n_train_samples = len(y_syn_train)\n",
    "        rect = mpl.patches.Rectangle(xy=(0,0), width=n_train_samples, height=1)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        #Plot each testing sample from this fold as a vertical line\n",
    "        for this_text_ix in test_index:\n",
    "            ax.plot([this_text_ix, this_text_ix], [0, 1], color=cmap(1),\n",
    "                    linewidth=0.75)\n",
    "\n",
    "        #Plot formatting\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(0, n_train_samples)\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        #Subplot titles\n",
    "        if fold_counter == 0:\n",
    "            ax.text(0.26, 1.2, 'Training data,',\n",
    "                    transform=ax.transAxes, backgroundcolor = cmap(0))\n",
    "            ax.text(0.45, 1.2, 'testing data:',\n",
    "                    transform=ax.transAxes, backgroundcolor = cmap(1))\n",
    "            ax.text(0.62, 1.2, 'fold {}'.format(fold_counter+1), transform=ax.transAxes)\n",
    "        else:\n",
    "            ax.text(0.45, 1.2, 'Fold {}'.format(fold_counter+1), transform=ax.transAxes)\n",
    "\n",
    "        fold_counter += 1\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kfolds(k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = StratifiedKFold(n_splits=n_folds, shuffle=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kfolds(k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kfolds(k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 18: Reducing Overfitting on the Synthetic Data Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val_exponents = np.linspace(3,-3,13)\n",
    "C_val_exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals = np.float(10)**C_val_exponents\n",
    "C_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_C_search(k_folds, C_vals, model, X, Y):\n",
    "    \n",
    "    n_folds = k_folds.n_splits\n",
    "    cv_train_roc_auc = np.empty((n_folds, len(C_vals)))\n",
    "    cv_test_roc_auc = np.empty((n_folds, len(C_vals)))\n",
    "    cv_test_roc = [[]]*len(C_vals)\n",
    "\n",
    "    for c_val_counter in range(len(C_vals)):\n",
    "        #Set the C value for the model object\n",
    "        model.C = C_vals[c_val_counter]\n",
    "        #Count folds for each value of C\n",
    "        fold_counter = 0\n",
    "        #Get training and testing indices for each fold\n",
    "        for train_index, test_index in k_folds.split(X, Y):\n",
    "            #Subset the features and response, for training and testing data for\n",
    "            #this fold\n",
    "            X_cv_train, X_cv_test = X[train_index], X[test_index]\n",
    "            y_cv_train, y_cv_test = Y[train_index], Y[test_index]\n",
    "\n",
    "            #Fit the model on the training data\n",
    "            model.fit(X_cv_train, y_cv_train)\n",
    "\n",
    "            #Get the training ROC AUC\n",
    "            y_cv_train_predict_proba = model.predict_proba(X_cv_train)\n",
    "            cv_train_roc_auc[fold_counter, c_val_counter] = \\\n",
    "            roc_auc_score(y_cv_train, y_cv_train_predict_proba[:,1])\n",
    "\n",
    "            #Get the testing ROC AUC\n",
    "            y_cv_test_predict_proba = model.predict_proba(X_cv_test)\n",
    "            cv_test_roc_auc[fold_counter, c_val_counter] = \\\n",
    "            roc_auc_score(y_cv_test, y_cv_test_predict_proba[:,1])\n",
    "\n",
    "            #Testing ROC curves for each fold\n",
    "            this_fold_roc = roc_curve(y_cv_test, y_cv_test_predict_proba[:,1])\n",
    "            cv_test_roc[c_val_counter].append(this_fold_roc)\n",
    "\n",
    "            #Increment the fold counter\n",
    "            fold_counter += 1\n",
    "\n",
    "        #Indicate progress\n",
    "        print('Done with C = {}'.format(lr_syn.C))\n",
    "\n",
    "    return cv_train_roc_auc, cv_test_roc_auc, cv_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_roc_auc, cv_test_roc_auc, cv_test_roc = \\\n",
    "cross_val_C_search(k_folds, C_vals, lr_syn, X_syn_train, y_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for this_fold in range(k_folds.n_splits):\n",
    "    plt.plot(C_val_exponents, cv_train_roc_auc[this_fold], '-o',\n",
    "             color=cmap(this_fold), label='Training fold {}'.format(this_fold+1))\n",
    "    plt.plot(C_val_exponents, cv_test_roc_auc[this_fold], '-x',\n",
    "             color=cmap(this_fold), label='Testing fold {}'.format(this_fold+1))\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('log$_{10}$(C)')\n",
    "plt.legend(loc = [1.1, 0.2])\n",
    "plt.title('Cross validation scores for each fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_test_roc_auc,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_train_roc_auc,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_roc_auc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C_val_exponents, np.mean(cv_train_roc_auc, axis=0), '-o',\n",
    "        label='Average training score')\n",
    "plt.plot(C_val_exponents, np.mean(cv_test_roc_auc, axis=0), '-x',\n",
    "        label='Average testing score')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('log$_{10}$(C)')\n",
    "plt.legend()\n",
    "plt.title('Cross validation scores averaged over all folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FPRs, TPRs, and thresholds for each fold, for each C value, are contained in the list of lists as tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cv_test_roc[9][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some FPRs\n",
    "cv_test_roc[9][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C_val_bool = C_val_exponents == -1.5\n",
    "best_C_val_bool.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C_val_ix = np.nonzero(best_C_val_bool.astype(int))\n",
    "best_C_val_ix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_fold in range(k_folds.n_splits):\n",
    "    fpr = cv_test_roc[best_C_val_ix[0][0]][this_fold][0]\n",
    "    tpr = cv_test_roc[best_C_val_ix[0][0]][this_fold][1]\n",
    "    plt.plot(fpr, tpr, label='Fold {}'.format(this_fold+1))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curves for each fold at C = $10^{-1.5}$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on all training data with best C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_syn.C = 10**(-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_syn.fit(X_syn_train, y_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_syn_train_predict_proba = lr_syn.predict_proba(X_syn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_syn_train, y_syn_train_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_syn_test_predict_proba = lr_syn.predict_proba(X_syn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_syn_test, y_syn_test_predict_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many coefficients did not get set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((lr_syn.coef_ != 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_syn.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 4: Cross-Validation and Feature Engineering with the Case Study Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset out the features for the case study data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_response[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df['default payment next month'].values,\n",
    "test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='saga', penalty='l1', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lr_pipeline = Pipeline(steps=[('scaler', min_max_sc), ('model', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lr_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lr_pipeline.get_params()['model__C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lr_pipeline.set_params(model__C = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val_exponents = np.linspace(2,-3,6)\n",
    "C_val_exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals = np.float(10)**C_val_exponents\n",
    "C_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_C_search_pipe(k_folds, C_vals, pipeline, X, Y):\n",
    "    \n",
    "    n_folds = k_folds.n_splits\n",
    "    cv_train_roc_auc = np.empty((n_folds, len(C_vals)))\n",
    "    cv_test_roc_auc = np.empty((n_folds, len(C_vals)))\n",
    "    cv_test_roc = [[]]*len(C_vals)\n",
    "\n",
    "    for c_val_counter in range(len(C_vals)):\n",
    "        #Set the C value for the model object\n",
    "        pipeline.set_params(model__C = C_vals[c_val_counter])\n",
    "        #Count folds for each value of C\n",
    "        fold_counter = 0\n",
    "        #Get training and testing indices for each fold\n",
    "        for train_index, test_index in k_folds.split(X, Y):\n",
    "            #Subset the features and response, for training and testing data for\n",
    "            #this fold\n",
    "            X_cv_train, X_cv_test = X[train_index], X[test_index]\n",
    "            y_cv_train, y_cv_test = Y[train_index], Y[test_index]\n",
    "\n",
    "            #Fit the model on the training data\n",
    "            pipeline.fit(X_cv_train, y_cv_train)\n",
    "\n",
    "            #Get the training ROC AUC\n",
    "            y_cv_train_predict_proba = pipeline.predict_proba(X_cv_train)\n",
    "            cv_train_roc_auc[fold_counter, c_val_counter] = \\\n",
    "            roc_auc_score(y_cv_train, y_cv_train_predict_proba[:,1])\n",
    "\n",
    "            #Get the testing ROC AUC\n",
    "            y_cv_test_predict_proba = pipeline.predict_proba(X_cv_test)\n",
    "            cv_test_roc_auc[fold_counter, c_val_counter] = \\\n",
    "            roc_auc_score(y_cv_test, y_cv_test_predict_proba[:,1])\n",
    "\n",
    "            #Testing ROC curves for each fold\n",
    "            this_fold_roc = roc_curve(y_cv_test, y_cv_test_predict_proba[:,1])\n",
    "            cv_test_roc[c_val_counter].append(this_fold_roc)\n",
    "\n",
    "            #Increment the fold counter\n",
    "            fold_counter += 1\n",
    "\n",
    "        #Indicate progress\n",
    "        print('Done with C = {}'.format(pipeline.get_params()['model__C']))\n",
    "\n",
    "    return cv_train_roc_auc, cv_test_roc_auc, cv_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_roc_auc, cv_test_roc_auc, cv_test_roc = \\\n",
    "cross_val_C_search_pipe(k_folds, C_vals, scale_lr_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C_val_exponents, np.mean(cv_train_roc_auc, axis=0), '-o',\n",
    "        label='Average training score')\n",
    "plt.plot(C_val_exponents, np.mean(cv_test_roc_auc, axis=0), '-x',\n",
    "        label='Average testing score')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('log$_{10}$(C)')\n",
    "plt.legend()\n",
    "plt.title('Cross validation on Case Study problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_test_roc_auc, axis=0)\n",
    "# array([0.7183383 , 0.71828489, 0.71698036, 0.71521589, 0.7164676 ,\n",
    "#        0.5       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like overfitting is happening. Our model may be underfitting. Let's try to engineer some new features to see if we can improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_interactions = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interact = make_interactions.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_interact, df['default payment next month'].values,\n",
    "test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_roc_auc, cv_test_roc_auc, cv_test_roc = \\\n",
    "cross_val_C_search_pipe(k_folds, C_vals, scale_lr_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C_val_exponents, np.mean(cv_train_roc_auc, axis=0), '-o',\n",
    "        label='Average training score')\n",
    "plt.plot(C_val_exponents, np.mean(cv_test_roc_auc, axis=0), '-x',\n",
    "        label='Average testing score')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('log$_{10}$(C)')\n",
    "plt.legend()\n",
    "plt.title('Cross validation on Case Study problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_test_roc_auc, axis=0)\n",
    "# array([0.73964018, 0.73938939, 0.73417501, 0.71595831, 0.7164676 ,\n",
    "#        0.5       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
